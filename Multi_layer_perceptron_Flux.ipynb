{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux\n",
    "using Flux.Data: DataLoader\n",
    "using Flux: onehotbatch, onecold, @epochs\n",
    "using Flux.Losses: logitcrossentropy\n",
    "using MLDatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ENV[\"DATADEPS_ALWAYS_ACCEPT\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       "\n",
       "Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       "\n",
       "Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       "\n",
       "...\n",
       "\n",
       "Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       "\n",
       "Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       "\n",
       "Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], [7, 2, 1, 0, 4, 1, 4, 9, 5, 9  …  7, 8, 9, 0, 1, 2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load full train set\n",
    "train_x, train_y = MLDatasets.MNIST.traindata(Float32)\n",
    "\n",
    "# load full test set\n",
    "test_x, test_y = MLDatasets.MNIST.testdata(Float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train set: (28, 28, 60000)\n",
      "Size of test set: (28, 28, 10000)\n"
     ]
    }
   ],
   "source": [
    "println(\"Size of train set: $(size(train_x))\")\n",
    "println(\"Size of test set: $(size(test_x))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to transform the MNIST data so we can feed it into our Flux model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784×10000 Array{Float32,2}:\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " ⋮                        ⋮              ⋱            ⋮                   \n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  …  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshape Data in order to flatten each image into a linear array\n",
    "train_x = Flux.flatten(train_x)\n",
    "test_x = Flux.flatten(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Bool[0 1 … 0 0; 0 0 … 0 0; … ; 0 0 … 0 1; 0 0 … 0 0], Bool[0 0 … 0 0; 0 0 … 0 0; … ; 0 0 … 0 0; 0 0 … 0 0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One-hot-encode the labels\n",
    "train_y, test_y = onehotbatch(train_y, 0:9), onehotbatch(test_y, 0:9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataLoader{Tuple{Array{Float32,2},Flux.OneHotMatrix{Array{Flux.OneHotVector,1}}}}((Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Bool[0 0 … 0 0; 0 0 … 0 0; … ; 0 0 … 0 0; 0 0 … 0 0]), 256, 10000, true, 10000, [1, 2, 3, 4, 5, 6, 7, 8, 9, 10  …  9991, 9992, 9993, 9994, 9995, 9996, 9997, 9998, 9999, 10000], false)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create DataLoaders (mini-batch iterators)\n",
    "train_data_loader = DataLoader((train_x, train_y), batchsize=256, shuffle=true)\n",
    "test_data_loader = DataLoader((test_x, test_y), batchsize=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function loss(data_loader, model)\n",
    "    total_loss = 0.0f0\n",
    "    #change num to something more meaningful\n",
    "    num_elements = 0\n",
    "    for (x, y) in data_loader\n",
    "        ŷ = model(x)\n",
    "        total_loss += logitcrossentropy(ŷ, y, agg=sum)\n",
    "        num_elements +=  size(x)[end]\n",
    "    end\n",
    "    return total_loss / num_elements\n",
    "end\n",
    "\n",
    "\n",
    "function accuracy(data_loader, model)\n",
    "    accuracy = 0\n",
    "    num_elements = 0\n",
    "    for (x, y) in data_loader\n",
    "        ŷ = model(x)\n",
    "        accuracy += sum(onecold(ŷ) .== onecold(y))\n",
    "        num_elements += size(x)[end]\n",
    "    end   \n",
    "    \n",
    "    return accuracy / num_elements\n",
    "end\n",
    "\n",
    "# Comment on why we need both: loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Params([Float32[-0.004591364 -0.029729255 … 0.07734814 -0.021867776; -0.023276465 -0.042033613 … -0.008883792 -0.011712046; … ; 0.06752823 0.07467249 … 0.06259729 0.010588841; -0.02407101 -0.07415057 … -0.0541573 0.011051903], Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], Float32[-0.18165545 -0.03709334 … -0.21325627 0.22060108; -0.35121942 -0.33347034 … -0.082487874 0.28123042; … ; 0.3670341 0.18998665 … -0.20228285 -0.14513235; 0.12589918 0.2982511 … -0.028587235 0.035729744], Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct model\n",
    "img_size = (28,28,1)\n",
    "n_classes = 10\n",
    "\n",
    "# Our model has one input layer, one hidden layer (with 32 neurons) and output layer, \n",
    "#each neuron in the hidden layer has inputs 28x28x1 and the output layer has n_classes neurons\n",
    "model = Chain( Dense(prod(img_size), 32, relu),\n",
    "                  Dense(32, n_classes))\n",
    "\n",
    "ps = Flux.params(model) # model's trainable parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ADAM(0.0003, (0.9, 0.999), IdDict{Any,Any}())"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " ## Optimizer\n",
    "η = 3e-4 \n",
    "\n",
    "opt = ADAM(η)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch=1\n",
      "  train_loss = 0.5584692, train_accuracy = 0.8673666666666666\n",
      "  test_loss = 0.53656596, test_accuracy = 0.8756\n",
      "Epoch=2\n",
      "  train_loss = 0.37753665, train_accuracy = 0.9006833333333333\n",
      "  test_loss = 0.36366037, test_accuracy = 0.9047\n",
      "Epoch=3\n",
      "  train_loss = 0.31881, train_accuracy = 0.9132833333333333\n",
      "  test_loss = 0.3089058, test_accuracy = 0.9163\n",
      "Epoch=4\n",
      "  train_loss = 0.28730088, train_accuracy = 0.9206166666666666\n",
      "  test_loss = 0.28172365, test_accuracy = 0.922\n",
      "Epoch=5\n",
      "  train_loss = 0.26431516, train_accuracy = 0.92645\n",
      "  test_loss = 0.2608685, test_accuracy = 0.9266\n",
      "Epoch=6\n",
      "  train_loss = 0.24699712, train_accuracy = 0.9318833333333333\n",
      "  test_loss = 0.24530308, test_accuracy = 0.93\n",
      "Epoch=7\n",
      "  train_loss = 0.23527534, train_accuracy = 0.9336666666666666\n",
      "  test_loss = 0.23613752, test_accuracy = 0.9327\n",
      "Epoch=8\n",
      "  train_loss = 0.22115913, train_accuracy = 0.9383\n",
      "  test_loss = 0.22409585, test_accuracy = 0.9349\n",
      "Epoch=9\n",
      "  train_loss = 0.21003546, train_accuracy = 0.9408166666666666\n",
      "  test_loss = 0.21367964, test_accuracy = 0.9386\n",
      "Epoch=10\n",
      "  train_loss = 0.20149066, train_accuracy = 0.9439333333333333\n",
      "  test_loss = 0.2060335, test_accuracy = 0.9395\n",
      "Epoch=11\n",
      "  train_loss = 0.19284342, train_accuracy = 0.9456\n",
      "  test_loss = 0.19808091, test_accuracy = 0.9419\n",
      "Epoch=12\n",
      "  train_loss = 0.18543862, train_accuracy = 0.9482833333333334\n",
      "  test_loss = 0.19141534, test_accuracy = 0.9442\n",
      "Epoch=13\n",
      "  train_loss = 0.17779881, train_accuracy = 0.9508833333333333\n",
      "  test_loss = 0.18416105, test_accuracy = 0.9457\n",
      "Epoch=14\n",
      "  train_loss = 0.17177446, train_accuracy = 0.9521666666666667\n",
      "  test_loss = 0.17932893, test_accuracy = 0.9481\n",
      "Epoch=15\n",
      "  train_loss = 0.16618085, train_accuracy = 0.9531833333333334\n",
      "  test_loss = 0.17416345, test_accuracy = 0.9498\n",
      "Epoch=16\n",
      "  train_loss = 0.16057213, train_accuracy = 0.9550666666666666\n",
      "  test_loss = 0.16914834, test_accuracy = 0.9502\n",
      "Epoch=17\n",
      "  train_loss = 0.15520048, train_accuracy = 0.95645\n",
      "  test_loss = 0.16629991, test_accuracy = 0.9521\n",
      "Epoch=18\n",
      "  train_loss = 0.15184678, train_accuracy = 0.9577666666666667\n",
      "  test_loss = 0.16211508, test_accuracy = 0.9534\n",
      "Epoch=19\n",
      "  train_loss = 0.1469155, train_accuracy = 0.9590333333333333\n",
      "  test_loss = 0.15823045, test_accuracy = 0.9545\n",
      "Epoch=20\n",
      "  train_loss = 0.142399, train_accuracy = 0.95995\n",
      "  test_loss = 0.1550037, test_accuracy = 0.9542\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "\n",
    "for epoch in 1:epochs\n",
    "    for (x, y) in train_data_loader\n",
    "        gs = gradient(() -> logitcrossentropy(model(x), y), ps) # compute gradient\n",
    "        Flux.Optimise.update!(opt, ps, gs) # update parameters\n",
    "     end\n",
    "        \n",
    "    # Compute accuracy and loss for all of the train and test data\n",
    "    train_loss = loss(train_data_loader, model)\n",
    "    train_acc = accuracy(train_data_loader, model)\n",
    "    test_loss = loss(test_data_loader, model)\n",
    "    test_acc = accuracy(test_data_loader, model)\n",
    "    println(\"Epoch=$epoch\")\n",
    "    println(\"  train_loss = $train_loss, train_accuracy = $train_acc\")\n",
    "    println(\"  test_loss = $test_loss, test_accuracy = $test_acc\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.2",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
